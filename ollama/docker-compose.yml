services:
  #https://hub.docker.com/r/ollama/ollama
  ai:
    image: ollama/ollama
    container_name: ai
    runtime: nvidia
    ports:
      - 11434:11434
    volumes:
      - ollama:/root/.ollama
  #docker compose exec ai nvidia-smi

  #https://docs.docker.com/desktop/gpu
  benchmark:
    image: nvcr.io/nvidia/k8s/cuda-sample:nbody
    container_name: benchmark
    runtime: nvidia
    command: nbody -gpu -benchmark  

volumes:
  ollama:
  